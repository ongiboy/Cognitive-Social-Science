{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link to git repository: https://github.com/ongiboy/Cognitive-Social-Science\n",
    "\n",
    "Group member's contribution:\n",
    "* Christian Ong (s204109)   : 33%\n",
    "* Daniel Ries (s21)         : 33%\n",
    "* Kavus Latifi (s21)        : 33%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Web-scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Setup the URL\n",
    "LINK = \"https://ic2s2-2023.org/program\"\n",
    "r = requests.get(LINK)\n",
    "soup = BeautifulSoup(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "# Find the sections with names\n",
    "sections = soup.find_all(\"ul\",{\"class\":\"nav_list\"})\n",
    "for section in sections:\n",
    "\n",
    "    # Find names within section\n",
    "    bullets = section.find_all(\"i\")\n",
    "    for nameline in bullets:\n",
    "\n",
    "        # Split into each name and add to list\n",
    "        names.extend(nameline.text.split(\", \"))\n",
    "\n",
    "# unique elements in names\n",
    "names = list(set(names))\n",
    "len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save names in csv\n",
    "df = pd.DataFrame(names, columns=[\"name\"])\n",
    "df.to_csv(\"names.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many unique researchers do you get?\n",
    "* 1475\n",
    "\n",
    "Explain the process you followed to web-scrape the page. \n",
    "Which choices did you make to accurately retreive as many names as possible? Which strategies did you use to assess the quality of your final list?\n",
    "* First, a detailed inspection of the page was made. The sections containing names were found and the names were extracted. \n",
    "* Then, the list was made to a set to remove potential duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Ready Made vs Custom Made Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are pros and cons of the custom-made data used in Centola's experiment (the first study presented in the lecture) and the ready-made data used in Nicolaides's study (the second study presented in the lecture)?\n",
    "* Centola's data samples and experimental setup were highly controlled, so the causal effect of clustered vs random networks on spread behavior could be investigated while avoiding confounding effects effectively. However, ethical aspects of transparency of the experimental data could be discussed, as the people registering to the health website were not informed about their participation of the experiment. The controlled set-up might also create an artificial environment not accurately reflecting clustered networks of the real world.  \n",
    "\n",
    "* The observational data from the fitness tracking app combined with the social network app used in Nicolaide's study, provided large samples under real world conditions, reflecting the users actual behaviors in their natural environments. However as control of data collecting were limited, potential biases in the app's user base can affect the generalizability of the findings. Other external variables may also affect the found correlation, such as the motivation or other explanations as homophily.  \n",
    "  \n",
    "\n",
    "How do you think these differences can influence the interpretation of the results in each study?\n",
    "* The findings of Centola's experiment are likely more internally valid because of the controlled setup which helps isolating the variables of interest and reduce external factors. This difference makes for a more clear understanding of the causal relationship between network structures and spread behavior. However, because of the artificial environment and lack of transparency, the results of Centolaâ€™s study may have limited external validity.\n",
    "* On the other side, the results of Nicolaide's study are more applicable to real-world scenarios, dealing with the complexity of actual social networks. However, because of the lack of control over the data collection there might be potential biases and confounding variables, making it necessary to interpret the findings with caution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Gatherin Research Articles using the OpenAlex API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset summary: How many works are listed in your IC2S2 papers dataframe?\n",
    "* ?\n",
    "\n",
    "Efficiency in code: Describe the strategies you implemented to make your code more efficient. How did your approach affect your code's execution time?\n",
    "* As many of the search filters as possible were moved to the filter parameter, as this resulted in fewer results to filter through.\n",
    "* Additionally, the search was done in batches of names, paging through the results (200 per page) and avoiding many pages with few results.\n",
    "* The names searched for was based on work from week 2. Here, the list was created from the names from week 1. If a name didn't contain all desired columns (eg. country_code), the name was dropped.\n",
    "\n",
    "Filtering Criteria and Dataset Relevance: Reflect on the rationale behind setting specific thresholds for the total number of works by an author, the citation count, the number of authors per work, and the relevance of works to specific fields. How do these filtering criteria contribute to the relevance of the dataset you compiled? \n",
    "* Filtering of field semantics ensures articles within out desired scientific field.\n",
    "* Citation thresholding to >10 citations ensures well-acknowledged articles.\n",
    "* Author thresholds on >5 works ensures that relevant and active authors are selected. Limiting to authors with <5000 articles attempts to limit to relevant authors within our desired field. Many articles increases the likelihood that the author is working on a very wide range of or in interdisciplinary fields, which could be an irrelevant author.\n",
    "* Thresholding to <10 authors per work also attempts to avoid very broad and non-specific (irrelevant) articles.\n",
    "\n",
    "Do you believe any aspects of Computational Social Science research might be underrepresented or overrepresented as a result of these choices?\n",
    "* On one hand, the thresholding could lead to the exclusion of too many authors, because they don't satisfy our thresholds.\n",
    "* But we believe that there is a greater amount of included irrelevant authors, eg. based on the semantic filters. For example, a random physics article with political importance would be included because of the semantic filters. This would be irrelevant to our search, and there are many other examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: The Network of Computational Social Scientists"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CompSS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
